# Streamlit Frontend for Robust OCR ‚Üí Financials Excel
# ----------------------------------------------------
# Features
# - Upload PDF or image(s)
# - OCR via OpenTyphoon API **or** local Tesseract (no-cost fallback)
# - Robust parsing of messy tables ‚Üí tidy DataFrames
# - Extract audit opinion
# - Balance validation + unmapped heading report
# - Preview & Download Excel

# How to run:
#   1) pip install -U streamlit pdf2image pillow pytesseract pandas rapidfuzz beautifulsoup4 lxml xlsxwriter
#   2) (Linux) apt-get install -y poppler-utils tesseract-ocr
#   3) streamlit run streamlit_frontend_app.py

import io
import re
import json
import tempfile
from io import StringIO
from typing import List, Tuple, Optional

import pandas as pd
import streamlit as st
from bs4 import BeautifulSoup
from PIL import Image
import pytesseract
from pytesseract import TesseractError, TesseractNotFoundError

# Optional fuzzy matcher
try:
    from rapidfuzz import fuzz, process
    USE_FUZZY = True
except Exception:
    USE_FUZZY = False

# ---------- OCR Backends ----------
# OpenTyphoon API
import requests

def ocr_opentyphoon(image_bytes: bytes, api_key: str, task_type: str = "default",
                    max_tokens: int = 16000, temperature: float = 0.1,
                    top_p: float = 0.6, repetition_penalty: float = 1.2,
                    pages: List[int] | None = None) -> str:
    url = "https://api.opentyphoon.ai/v1/ocr"
    files = {"file": ("page.png", image_bytes)}
    data = {
        "task_type": task_type,
        "max_tokens": str(max_tokens),
        "temperature": str(temperature),
        "top_p": str(top_p),
        "repetition_penalty": str(repetition_penalty),
    }
    if pages:
        data["pages"] = json.dumps(pages)
    headers = {"Authorization": f"Bearer {api_key}"}
    resp = requests.post(url, files=files, data=data, headers=headers, timeout=120)
    resp.raise_for_status()
    result = resp.json()
    texts = []
    for page_result in result.get("results", []):
        if page_result.get("success") and page_result.get("message"):
            content = page_result["message"]["choices"][0]["message"]["content"]
            try:
                parsed = json.loads(content)
                text = parsed.get("natural_text", content)
            except json.JSONDecodeError:
                text = content
            texts.append(text)
    return "\n".join(texts)

# Local Tesseract fallback
try:
    import pytesseract
    TESSERACT_AVAILABLE = True
except Exception:
    TESSERACT_AVAILABLE = False

from pdf2image import convert_from_bytes

# ---------- Parsing Utilities (Robust) ----------
THAI_DIGITS = str.maketrans("‡πê‡πë‡πí‡πì‡πî‡πï‡πñ‡πó‡πò‡πô", "0123456789")
DASHES = {"-", "‚Äì", "‚Äî", ""}

ALIASES_REGEX = {
    "‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î‡πÅ‡∏•‡∏∞‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î": [r"‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î(‡πÅ‡∏•‡∏∞)?‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£‡πÄ‡∏ó‡∏µ‡∏¢‡∏ö‡πÄ‡∏ó‡πà‡∏≤(‡πÄ‡∏á‡∏¥‡∏ô‡∏™‡∏î)?", r"cash.*equivalent"],
    "‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤‡πÅ‡∏•‡∏∞‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏≠‡∏∑‡πà‡∏ô": [r"‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤(‡πÅ‡∏•‡∏∞|,)?\s*‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏≠‡∏∑‡πà‡∏ô", r"‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏Å‡∏≤‡∏£‡∏Ñ‡πâ‡∏≤(?!.*‡∏™‡∏∏‡∏ó‡∏ò‡∏¥)", r"‡∏•‡∏π‡∏Å‡∏´‡∏ô‡∏µ‡πâ‡∏≠‡∏∑‡πà‡∏ô(?!.*‡∏™‡∏∏‡∏ó‡∏ò‡∏¥)"],
    "‡∏£‡∏ß‡∏°‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô": [r"^‡∏£‡∏ß‡∏°\s*‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå\s*‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô$"],
    "‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô ‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£‡πÅ‡∏•‡∏∞‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå": [r"(‡∏ó‡∏µ‡πà‡∏î‡∏¥‡∏ô|‡∏≠‡∏≤‡∏Ñ‡∏≤‡∏£|‡∏≠‡∏∏‡∏õ‡∏Å‡∏£‡∏ì‡πå)"],
    "‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡πÑ‡∏°‡πà‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô‡∏≠‡∏∑‡πà‡∏ô": [r"‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå‡πÑ‡∏°‡πà‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô(‡∏≠‡∏∑‡πà‡∏ô|‡∏£‡∏ß‡∏°‡∏≠‡∏∑‡πà‡∏ô)"],
    "‡∏£‡∏ß‡∏°‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô": [r"^‡∏£‡∏ß‡∏°\s*‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô\s*‡∏´‡∏°‡∏∏‡∏ô‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô$"],
    "‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ‡∏¢‡∏∑‡∏°‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô": [r"‡πÄ‡∏á‡∏¥‡∏ô‡∏Å‡∏π‡πâ(‡∏¢‡∏∑‡∏°)?\s*‡∏£‡∏∞‡∏¢‡∏∞‡∏™‡∏±‡πâ‡∏ô"],
    "‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß‡∏ó‡∏µ‡πà‡∏ñ‡∏∂‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î‡∏ä‡∏≥‡∏£‡∏∞‡∏†‡∏≤‡∏¢‡πÉ‡∏ô‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏µ": [r"‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô‡∏£‡∏∞‡∏¢‡∏∞‡∏¢‡∏≤‡∏ß.*(‡∏ñ‡∏∂‡∏á‡∏Å‡∏≥‡∏´‡∏ô‡∏î|‡∏Ñ‡∏£‡∏ö‡∏Å‡∏≥‡∏´‡∏ô‡∏î).*‡∏´‡∏ô‡∏∂‡πà‡∏á‡∏õ‡∏µ"],
}

KW_ASSET = r"(‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå|asset)"
KW_LIAB_EQUITY = r"(‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô|‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô|liabilit|equity)"
KW_PL = r"(‡∏£‡∏≤‡∏¢‡πÑ‡∏î‡πâ|‡∏Å‡∏≥‡πÑ‡∏£|‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô|income|profit|loss)"


def normalize_text(s: str) -> str:
    s = (s or "").lower()
    s = re.sub(r"\s+", " ", s)
    s = s.replace("‡∏Ø", "‡πÄ‡∏ß‡∏µ‡∏¢‡∏ô")
    return s.strip()


def map_heading_to_canonical(item: str, threshold: int = 88) -> Tuple[str | None, int]:
    t = normalize_text(item)
    for canonical, patterns in ALIASES_REGEX.items():
        for p in patterns:
            if re.search(p, t):
                return canonical, 100
    if USE_FUZZY:
        candidates = list(ALIASES_REGEX.keys())
        best = process.extractOne(t, candidates, scorer=fuzz.token_set_ratio)
        if best and best[1] >= threshold:
            return best[0], best[1]
    return None, 0


def apply_heading_mapping(df: pd.DataFrame) -> Tuple[pd.DataFrame, list]:
    if "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£" not in df.columns:
        return df, []
    mapped, unmapped = [], []
    for x in df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].astype(str).tolist():
        canon, score = map_heading_to_canonical(x)
        if canon:
            mapped.append(canon)
        else:
            mapped.append(x)
            unmapped.append(x)
    out = df.copy()
    out["‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠_‡∏°‡∏≤‡∏ï‡∏£‡∏ê‡∏≤‡∏ô"] = mapped
    return out, sorted(set(unmapped))


def parse_number(raw: str, unit_multiplier=1.0):
    if pd.isna(raw):
        return pd.NA
    s = str(raw).strip().translate(THAI_DIGITS)
    if s in DASHES:
        return pd.NA
    neg = False
    if re.match(r"^\(\s*.+\s*\)$", s):
        neg = True
        s = s.strip()[1:-1].strip()
    s = s.replace(",", "").replace("\u200b", "")
    m = re.search(r"-?\d+(\.\d+)?", s)
    if not m:
        return pd.NA
    val = float(m.group(0)) * unit_multiplier
    return -val if neg else val


def detect_unit_multiplier(extracted_text: str):
    hint = extracted_text.lower()
    if "‡∏•‡πâ‡∏≤‡∏ô‡∏ö‡∏≤‡∏ó" in hint:
        return 1_000_000.0
    if "‡∏û‡∏±‡∏ô‡∏ö‡∏≤‡∏ó" in hint:
        return 1_000.0
    return 1.0


def extract_year_text(s):
    m = re.search(r"(25\d{2}|20\d{2})", str(s))
    return m.group(0) if m else str(s)


def rename_year_columns(df: pd.DataFrame):
    new_cols, seen = [], {}
    for c in df.columns:
        if c in ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏"]:
            new_cols.append(c)
            continue
        col = extract_year_text(c)
        if col in seen:
            seen[col] += 1
            col = f"{col}_{seen[col]}"
        else:
            seen[col] = 1
        new_cols.append(col)
    df.columns = new_cols
    return df


def guess_plaintext_tables(text: str):
    lines = [l for l in text.splitlines() if l.strip()]
    blocks, cur = [], []
    for ln in lines:
        if re.search(r"\s{2,}|\t", ln):
            cur.append(ln)
        else:
            if cur:
                blocks.append("\n".join(cur))
                cur = []
    if cur:
        blocks.append("\n".join(cur))
    return blocks


def plaintext_block_to_df(block: str):
    rows = []
    for ln in block.splitlines():
        parts = re.split(r"\t+|\s{2,}", ln.strip())
        if len(parts) >= 2:
            rows.append(parts)
    if not rows:
        return None
    max_len = max(len(r) for r in rows)
    for r in rows:
        if len(r) < max_len:
            r.extend([""] * (max_len - len(r)))
    cols = [f"col_{i}" for i in range(max_len)]
    df = pd.DataFrame(rows, columns=cols)
    df = df.rename(columns={df.columns[0]: "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"})
    return df


def read_tables_from_html(extracted_text: str) -> List[pd.DataFrame]:
    tables: List[pd.DataFrame] = []
    # Try direct read_html
    try:
        dfs = pd.read_html(StringIO(extracted_text))
        tables.extend(dfs)
    except Exception:
        pass
    # Parse <table> tags precisely
    try:
        soup = BeautifulSoup(extracted_text, "html.parser")
        for t in soup.find_all("table"):
            try:
                dfx = pd.read_html(StringIO(str(t)))  # wrap with StringIO to silence FutureWarning
                tables.extend(dfx)
            except Exception:
                continue
    except Exception:
        pass
    # Fallback plaintext ‚Üí pseudo tables
    if not tables:
        blocks = guess_plaintext_tables(extracted_text)
        for b in blocks:
            try:
                df = plaintext_block_to_df(b)
                if df is not None and df.shape[1] >= 2:
                    tables.append(df)
            except Exception:
                continue
    return tables


def tidy_table(df_raw: pd.DataFrame, unit_multiplier: float) -> pd.DataFrame:
    df = df_raw.copy()
    if df.empty or df.shape[1] == 0:
        return pd.DataFrame()
    if isinstance(df.columns, pd.MultiIndex):
        df.columns = ["_".join([str(x) for x in tup if str(x) != "nan"]).strip() for tup in df.columns]
    # choose an item column
    text_cols = [c for c in df.columns if df[c].dtype == "object"]
    candidate_item_col = (text_cols[0] if text_cols else df.columns[0])
    if candidate_item_col != "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£":
        df = df.rename(columns={candidate_item_col: "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"})
    df = rename_year_columns(df)
    # detect numeric/year columns
    year_cols = []
    for c in df.columns:
        if c in ["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏"]:
            continue
        if re.fullmatch(r"\d{4}(_\d+)?", str(c)):
            year_cols.append(c)
            continue
        sample = df[c].astype(str).head(20).tolist()
        numeric_like = 0
        for v in sample:
            vv = v.translate(THAI_DIGITS).replace(",", "").replace("\u200b", "").strip()
            if vv in DASHES or re.search(r"-?\d+(\.\d+)?", vv):
                numeric_like += 1
        if len(sample) > 0 and numeric_like / len(sample) >= 0.6:
            year_cols.append(c)
    for c in year_cols:
        df[c] = df[c].apply(lambda v: parse_number(v, unit_multiplier=unit_multiplier))
    if "‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏" not in df.columns:
        df["‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏"] = pd.NA
    has_item_col = "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£" in df.columns
    if year_cols:
        numeric_mask = ~df[year_cols].isna().all(axis=1)
        item_mask = df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].notna() if has_item_col else False
        mask_keep = numeric_mask | item_mask
        df = df[mask_keep].reset_index(drop=True)
    ordered = (["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"] if has_item_col else []) + year_cols + ["‡∏´‡∏°‡∏≤‡∏¢‡πÄ‡∏´‡∏ï‡∏∏"]
    ordered = [c for c in ordered if c in df.columns]
    df = df[ordered]
    if "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£" not in df.columns:
        df.insert(0, "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£", pd.NA)
    return df


def classify_table(df: pd.DataFrame) -> str:
    if "‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£" not in df.columns:
        return "unknown"
    text = " ".join(df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].astype(str).tolist()).lower()
    score_asset = bool(re.search(KW_ASSET, text))
    score_liab  = bool(re.search(KW_LIAB_EQUITY, text))
    score_pl    = bool(re.search(KW_PL, text))
    if score_asset and not (score_liab or score_pl):
        return "asset"
    if score_liab and not score_asset:
        return "liab_eq"
    if score_pl:
        return "pl"
    return "unknown"


def extract_audit_opinion_html(extracted_text: str) -> str:
    soup = BeautifulSoup(extracted_text, "html.parser")
    full_text = soup.get_text("\n", strip=True)
    return extract_audit_opinion_text(full_text)


def extract_audit_opinion_text(full_text: str) -> str:
    txt = re.sub(r"[ \t]+", " ", full_text)
    patterns = [
        (r"(‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ[^\n]*)([\s\S]+?)(‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô|‡∏á‡∏ö\s)", True),
        (r"(‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ[^\n]*)([\s\S]+?)(‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô|‡∏á‡∏ö\s)", True),
    ]
    for pat, _ in patterns:
        m = re.search(pat, txt)
        if m:
            head = m.group(1).strip()
            body = m.group(2).strip()
            return f"{head}\n{body}".strip()
    lines = [l.strip() for l in txt.splitlines() if l.strip()]
    found = [l for l in lines if ("‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ" in l or "‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏´‡πá‡∏ô" in l or "‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô" in l)]
    return "\n".join(found) if found else "‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏Ñ‡∏¥‡∏î‡πÄ‡∏´‡πá‡∏ô‡∏ú‡∏π‡πâ‡∏™‡∏≠‡∏ö‡∏ö‡∏±‡∏ç‡∏ä‡∏µ"


def basic_balance_check(bs_df: pd.DataFrame):
    if bs_df.empty:
        return {"status": "empty", "notes": "no balance sheet rows"}
    asset_total_rows = bs_df[bs_df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].astype(str).str.contains("‡∏£‡∏ß‡∏°‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå")]
    liab_rows = bs_df[bs_df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].astype(str).str.contains("‡∏£‡∏ß‡∏°‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô")]
    equity_rows = bs_df[bs_df["‡∏£‡∏≤‡∏¢‡∏Å‡∏≤‡∏£"].astype(str).str.contains("‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô|‡∏£‡∏ß‡∏°‡∏™‡πà‡∏ß‡∏ô‡∏Ç‡∏≠‡∏á‡∏ú‡∏π‡πâ‡∏ñ‡∏∑‡∏≠‡∏´‡∏∏‡πâ‡∏ô")]
    year_cols = [c for c in bs_df.columns if re.fullmatch(r"\d{4}(_\d+)?", str(c))]
    issues = []
    for c in year_cols:
        a = asset_total_rows[c].dropna()
        l = liab_rows[c].dropna()
        e = equity_rows[c].dropna()
        if not a.empty and (not l.empty or not e.empty):
            lhs = a.iloc[-1]
            rhs = (l.iloc[-1] if not l.empty else 0) + (e.iloc[-1] if not e.empty else 0)
            if pd.notna(lhs) and pd.notna(rhs):
                if abs(lhs - rhs) > max(1e-6, abs(lhs) * 0.02):
                    issues.append(f"‡∏õ‡∏µ {c}: ‡∏£‡∏ß‡∏°‡∏™‡∏¥‡∏ô‡∏ó‡∏£‡∏±‡∏û‡∏¢‡πå {lhs:,.0f} != ‡∏´‡∏ô‡∏µ‡πâ‡∏™‡∏¥‡∏ô+‡∏ó‡∏∏‡∏ô {rhs:,.0f}")
    status = "ok" if not issues else "mismatch"
    return {"status": status, "notes": "; ".join(issues) if issues else ""}


def process_extracted_text(extracted_text: str, export_path_excel="‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô_clean.xlsx"):
    unit_mult = detect_unit_multiplier(extracted_text)
    tables = read_tables_from_html(extracted_text)

    assets, liab_eq, pl, unknowns = [], [], [], []
    unmapped_all = set()

    for t in tables:
        t = tidy_table(t, unit_multiplier=unit_mult)
        if t.empty or t.shape[1] < 2:
            continue
        t2, unmapped = apply_heading_mapping(t)
        unmapped_all.update(unmapped)
        kind = classify_table(t2)
        if kind == "asset":
            assets.append(t2)
        elif kind == "liab_eq":
            liab_eq.append(t2)
        elif kind == "pl":
            pl.append(t2)
        else:
            unknowns.append(t2)

    asset_df = pd.concat(assets, ignore_index=True) if assets else pd.DataFrame()
    liab_eq_df = pd.concat(liab_eq, ignore_index=True) if liab_eq else pd.DataFrame()
    pl_df = pd.concat(pl, ignore_index=True) if pl else pd.DataFrame()

    if not asset_df.empty or not liab_eq_df.empty:
        bs_df = pd.concat([d for d in [asset_df, liab_eq_df] if not d.empty], ignore_index=True)
    else:
        bs_df = pd.DataFrame()

    try:
        audit_opinion = extract_audit_opinion_html(extracted_text)
    except Exception:
        audit_opinion = extract_audit_opinion_text(extracted_text)

    bs_check = basic_balance_check(bs_df) if not bs_df.empty else {"status": "no_bs", "notes": ""}

    with pd.ExcelWriter(export_path_excel, engine="xlsxwriter") as writer:
        if not bs_df.empty:
            bs_df.to_excel(writer, sheet_name="‡∏á‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ê‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", index=False)
        if not pl_df.empty:
            pl_df.to_excel(writer, sheet_name="‡∏á‡∏ö‡∏Å‡∏≥‡πÑ‡∏£‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô", index=False)
        if unknowns:
            pd.concat(unknowns, ignore_index=True).to_excel(writer, sheet_name="unknown_tables", index=False)
        meta_rows = [
            {"key": "unit_multiplier", "value": unit_mult},
            {"key": "balance_check", "value": bs_check["status"]},
            {"key": "balance_notes", "value": bs_check["notes"]},
            {"key": "unmapped_headings", "value": "; ".join(sorted(unmapped_all)) if unmapped_all else ""},
        ]
        pd.DataFrame(meta_rows).to_excel(writer, sheet_name="meta", index=False)
        pd.DataFrame([{"audit_opinion": audit_opinion}]).to_excel(writer, sheet_name="audit_opinion", index=False)
        wb = writer.book
        num_fmt = wb.add_format({"num_format": "#,##0"})
        for sheet in ["‡∏á‡∏ö‡πÅ‡∏™‡∏î‡∏á‡∏ê‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô", "‡∏á‡∏ö‡∏Å‡∏≥‡πÑ‡∏£‡∏Ç‡∏≤‡∏î‡∏ó‡∏∏‡∏ô", "unknown_tables"]:
            if sheet in writer.sheets:
                ws = writer.sheets[sheet]
                ws.set_column(0, 0, 50)
                for col_idx in range(1, 50):
                    ws.set_column(col_idx, col_idx, 18, num_fmt)

    return {
        "balance_check": bs_check,
        "unmapped": sorted(unmapped_all),
        "export_path": export_path_excel,
        "has_bs": not bs_df.empty,
        "has_pl": not pl_df.empty,
        "unknown_count": len(unknowns),
    }

def process_image_ocr(pil_img: Image.Image, tess_langs: str = 'tha+eng') -> Optional[str]:
    """Process image with Tesseract OCR.
    
    Args:
        pil_img: PIL Image object
        tess_langs: Tesseract language string
    Returns:
        Extracted text or None if error occurs
    """
    try:
        text = pytesseract.image_to_string(pil_img, lang=tess_langs)
        return text
    except (TesseractError, TesseractNotFoundError) as e:
        st.error(f"OCR Error: {str(e)}")
        st.info("Please check if Tesseract is properly installed")
        return None

# ---------- Streamlit UI ----------
st.set_page_config(page_title="OCR ‚Üí Financials Excel", layout="wide")
st.title("üìÑ OCR ‚Üí ‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô (Excel)")

with st.sidebar:
    st.header("‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ OCR")
    ocr_backend = st.radio("‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ß‡∏¥‡∏ò‡∏µ OCR", ["OpenTyphoon API", "Tesseract (‡∏≠‡∏≠‡∏ü‡πÑ‡∏•‡∏ô‡πå)"]) 
    if ocr_backend == "OpenTyphoon API":
        api_key = st.text_input("OpenTyphoon API Key", type="password")
        task_type = st.selectbox("task_type", ["default", "table", "text"] , index=0)
        max_tokens = st.number_input("max_tokens", 1000, 32000, 16000, step=1000)
        temperature = st.number_input("temperature", 0.0, 1.0, 0.1, step=0.1)
        top_p = st.number_input("top_p", 0.0, 1.0, 0.6, step=0.05)
        repetition_penalty = st.number_input("repetition_penalty", 0.5, 2.0, 1.2, step=0.1)
    else:
        if not TESSERACT_AVAILABLE:
            st.warning("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏û‡∏ö pytesseract: ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏î‡πâ‡∏ß‡∏¢ `pip install pytesseract` ‡πÅ‡∏•‡∏∞‡∏•‡∏á `tesseract-ocr` ‡πÉ‡∏ô‡∏£‡∏∞‡∏ö‡∏ö")
        tess_langs = st.text_input("‡∏†‡∏≤‡∏©‡∏≤ OCR (‡πÄ‡∏ä‡πà‡∏ô tha+eng)", value="tha+eng")

    st.header("‡∏Å‡∏≤‡∏£‡πÅ‡∏õ‡∏•‡∏á PDF")
    dpi = st.slider("DPI (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PDF ‚Üí ‡∏†‡∏≤‡∏û)", 200, 500, 350, step=50)

uploaded = st.file_uploader("‡∏≠‡∏±‡∏õ‡πÇ‡∏´‡∏•‡∏î PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û (PNG/JPG)", type=["pdf", "png", "jpg", "jpeg"], accept_multiple_files=False)

if uploaded:
    st.info("‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° '‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•' ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏£‡∏¥‡πà‡∏° OCR ‡πÅ‡∏•‡∏∞‡∏™‡∏£‡πâ‡∏≤‡∏á Excel")
    if st.button("üöÄ ‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•"):
        try:
            file_bytes = uploaded.read()
            pages_images: List[Image.Image] = []
            if uploaded.type == "application/pdf":
                pages_images = convert_from_bytes(file_bytes, dpi=dpi)
            else:
                pages_images = [Image.open(io.BytesIO(file_bytes)).convert("RGB")]

            extracted_parts: List[str] = []
            prog = st.progress(0)
            for i, pil_img in enumerate(pages_images, start=1):
                buf = io.BytesIO()
                pil_img.save(buf, format="PNG")
                img_bytes = buf.getvalue()

                if ocr_backend == "OpenTyphoon API":
                    if not api_key:
                        st.error("‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà API Key ‡∏Å‡πà‡∏≠‡∏ô")
                        st.stop()
                    text = ocr_opentyphoon(img_bytes, api_key=api_key, task_type=task_type,
                                           max_tokens=max_tokens, temperature=temperature,
                                           top_p=top_p, repetition_penalty=repetition_penalty,
                                           pages=[i])
                else:
                    if not TESSERACT_AVAILABLE:
                        st.error("‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏°‡∏µ Tesseract ‡∏ï‡∏¥‡∏î‡∏ï‡∏±‡πâ‡∏á‡∏ö‡∏ô‡∏£‡∏∞‡∏ö‡∏ö‡∏ô‡∏µ‡πâ")
                        st.stop()
                    text = process_image_ocr(pil_img)

                extracted_parts.append(text)
                prog.progress(i / len(pages_images))

            extracted_text = "\n\n".join(extracted_parts)

            st.subheader("‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ó‡∏µ‡πà OCR ‡πÑ‡∏î‡πâ (‡∏¢‡πà‡∏≠)")
            st.code(extracted_text[:3000] + ("..." if len(extracted_text) > 3000 else ""))

            st.subheader("üîß ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏≤‡∏£‡∏≤‡∏á + Excel")
            result = process_extracted_text(extracted_text, export_path_excel="‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô_clean.xlsx")

            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Balance check", result["balance_check"]["status"])
            with col2:
                st.metric("Unknown tables", result["unknown_count"])
            with col3:
                st.metric("Unmapped headings", len(result["unmapped"]))

            if result["unmapped"]:
                with st.expander("‡∏î‡∏π‡∏´‡∏±‡∏ß‡∏Ç‡πâ‡∏≠‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÅ‡∏°‡πá‡∏õ (‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏±‡∏ö alias)"):
                    st.write(result["unmapped"]) 

            # Download buttons
            with open(result["export_path"], "rb") as f:
                st.download_button("‚¨áÔ∏è ‡∏î‡∏≤‡∏ß‡∏ô‡πå‡πÇ‡∏´‡∏•‡∏î‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô (Excel)", data=f, file_name="‡∏á‡∏ö‡∏Å‡∏≤‡∏£‡πÄ‡∏á‡∏¥‡∏ô_clean.xlsx",
                                   mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet")

            st.success("‡πÄ‡∏™‡∏£‡πá‡∏à‡πÅ‡∏•‡πâ‡∏ß!")
        except Exception as e:
            st.exception(e)
else:
    st.caption("‡∏£‡∏≠‡∏á‡∏£‡∏±‡∏ö PDF ‡∏´‡∏£‡∏∑‡∏≠‡∏£‡∏π‡∏õ‡πÄ‡∏î‡∏µ‡πà‡∏¢‡∏ß (PNG/JPG)")
